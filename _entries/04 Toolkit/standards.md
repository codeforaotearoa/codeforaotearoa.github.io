---
sectionid: standards
sectionclass: h2
parent-id: toolkit
is-parent: yes
title: Open Data Standards
number: 4200
---

Open Data is spreading across the globe, however by majority, this is happening without well documented standards, and the result is inconsistent meta-data, no uniform approval process, no uniform normalisation process and conflicting terms of use. All making it difficult for users to discover or use the data they want and need.

This is not just limited to different countries or organisations. Open data is hard to compare even across teams located in the same building.

## What are standards with respect to open data? And why do we need them?

Standards mean something widely accepted, agreed upon, or an established means of determining what a dataset should be.

This is to allow datasets from different sources to be easily comparable, joined into something bigger, to support wider research, knowledge exchange, app scalability and in general to make it easy to add value.

Once defined, the process will help make releasing a dataset easier.

This also aligns with the concept of frictionless data that was introduced by Open Knowledge Foundation.

Some examples of uniformity in datasets are: similar data and time format across all datasets, having minimum required fields, and similar dataset across different agencies should have similar structure and fields

This needs to be taken up as an elaborate API design initiative that should involve representative from all government agencies. A collaborative effort done once can save a lot of time in the hindsight.

A few examples of standards are:
- [Open Council Data Standard Australia](standards.opencouncildata.org)
- [W3C open data standards](https://www.w3.org/TR/dwbp)
- [Open Data Handbook Standards](opendatahandbook.org/resources/#standards)
- [Frictionless Data](https://okfn.org/projects/frictionless-data)
